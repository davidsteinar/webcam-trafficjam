{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pprint\n",
    "import pycurl\n",
    "from io import BytesIO\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/my_tf_model\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# we want the variable values from from my_tf_model (not working right now)\n",
    "saver = tf.train.import_meta_graph('models/my_tf_model.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "def conv_net(x,reuse=a, dropout=0.1610, kernel_size=3, filters=32, hiddenunits=500):\n",
    "    # Define a scope for reusing the variables\n",
    "    # with tf.variable_scope('model', reuse=reuse): is this needed?\n",
    "    conv1    = tf.layers.conv2d(inputs=x,\n",
    "                                filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                activation=tf.nn.relu)\n",
    "    maxpool1 = tf.layers.max_pooling2d(inputs=conv1,\n",
    "                                       pool_size=2,\n",
    "                                       strides=2)\n",
    "    conv2    = tf.layers.conv2d(inputs=maxpool1,\n",
    "                                filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                activation=tf.nn.relu)\n",
    "    maxpool2 = tf.layers.max_pooling2d(inputs=conv2,\n",
    "                                       pool_size=2,\n",
    "                                       strides=2)\n",
    "    conv3    = tf.layers.conv2d(inputs=maxpool2,\n",
    "                                filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                activation=tf.nn.relu)\n",
    "    maxpool3 = tf.layers.max_pooling2d(inputs=conv2,\n",
    "                                       pool_size=2,\n",
    "                                       strides=2)\n",
    "    flat     = tf.contrib.layers.flatten(inputs=maxpool3)\n",
    "    dropout1 = tf.layers.dropout(inputs=flat,\n",
    "                                 rate=dropout,\n",
    "                                 training=True)\n",
    "    dense1   = tf.layers.dense(inputs=dropout1,\n",
    "                               units=hiddenunits,\n",
    "                               activation=tf.nn.relu)\n",
    "\n",
    "    dropout2 = tf.layers.dropout(inputs=dense1,\n",
    "                                 rate=dropout,\n",
    "                                 training=True)\n",
    "    out = tf.layers.dense(dropout2,\n",
    "                          units=1)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summaries', 'trainable_variables', 'train_op', 'variables', 'queue_runners', 'update_ops']\n",
      "730\n"
     ]
    }
   ],
   "source": [
    "print(graph.get_all_collection_keys())\n",
    "print(len(graph.get_collection('trainable_variables')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns prediction of number of cars from img of dimensions 200x112x3\n",
    "def count_from_image(img):\n",
    "    print(\"build graph\")\n",
    "    c = conv_net(img, reuse=True)\n",
    "    print(\"done\")\n",
    "    return c\n",
    "\n",
    "# returns image from webcam with id\n",
    "def get_img(webcam_id):\n",
    "    image = tf.read_file(\"data/test_image.jpg\")\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize_images(image, [112, 200])\n",
    "    return tf.expand_dims(image,0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build graph\n",
      "Tensor(\"ExpandDims_111:0\", shape=(1, 112, 200, 3), dtype=float32)\n",
      "Tensor(\"conv2d_82/Relu:0\", shape=(1, 110, 198, 32), dtype=float32)\n",
      "done\n",
      "INFO:tensorflow:Restoring parameters from models/my_tf_model\n",
      "Webcam 33 has [[ 34.11844254]] number of cars\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-b19920d9b4b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Webcam \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" has \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" number of cars\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "webcam_id_list = [33] #dummy values\n",
    "sleep_time = 60 #check every minute\n",
    "while(1):\n",
    "    for w in webcam_id_list:\n",
    "        i = get_img(w)\n",
    "        g = count_from_image(i)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # forward prop the img and recieve prediction\n",
    "        count = sess.run(g)\n",
    "        print(\"Webcam \" + str(w) + \" has \" + str(count[[0]]) + \" number of cars\")\n",
    "    time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
